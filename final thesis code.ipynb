{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b1eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from tryagain import X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d6384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      \"\"\"\"\n",
    "b001 = pd.read_table(\"C:/Users/yirimeah/Test_1a/Data/_b3001_data.txt\",header=None)\n",
    "                      \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f46aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 13).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 13).T\n",
    "\n",
    "#Y_train = np.eye(13)[Y_train_orig.reshape(-1)].T\n",
    "#Y_test = np.eye(13)[Y_test_orig.reshape(-1)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc3f071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 78\n",
      "number of test examples = 26\n",
      "X_train shape: (78, 30, 30, 1)\n",
      "Y_train shape: (78, 13)\n",
      "X_test shape: (26, 30, 30, 1)\n",
      "Y_test shape: (26, 13)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1e8335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 12\n",
    "plt.imshow(X_train_orig[index]) #display sample training image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41179a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape):\n",
    "\n",
    "\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    Z1 = tf.keras.layers.Conv2D(8, (4, 4), strides = (1, 1), padding = 'same')(input_img)\n",
    "    A1 = tf.keras.layers.ReLU()(Z1)\n",
    "    P1 = tf.keras.layers.MaxPool2D(pool_size = (8, 8), strides = (8, 8), padding = 'same')(A1)\n",
    "    Z2 = tf.keras.layers.Conv2D(16, (2, 2), strides = (1, 1), padding = 'same')(P1)\n",
    "    A2 = tf.keras.layers.ReLU()(Z2)\n",
    "    P2 = tf.keras.layers.MaxPool2D(pool_size = (4, 4), strides= (4, 4), padding = 'same')(A2)\n",
    "    F = tf.keras.layers.Flatten()(P2)\n",
    "    outputs = tf.keras.layers.Dense(units = 13, activation = 'softmax')(F)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b07bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 30, 30, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 30, 30, 8)         136       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 30, 30, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 4, 4, 8)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 16)          528       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 4, 4, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 1, 1, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 13)                221       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 885\n",
      "Trainable params: 885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = convolutional_model((30, 30, 1))\n",
    "conv_model.compile(optimizer= Adam(0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b993fa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 113ms/step - loss: 2.6073 - accuracy: 0.0769 - val_loss: 2.6305 - val_accuracy: 0.0769\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.5866 - accuracy: 0.0769 - val_loss: 2.6166 - val_accuracy: 0.1154\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.5709 - accuracy: 0.1026 - val_loss: 2.6045 - val_accuracy: 0.1154\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 2.5587 - accuracy: 0.1154 - val_loss: 2.5946 - val_accuracy: 0.1154\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5483 - accuracy: 0.1538 - val_loss: 2.5865 - val_accuracy: 0.1154\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5385 - accuracy: 0.1667 - val_loss: 2.5793 - val_accuracy: 0.1154\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5299 - accuracy: 0.1795 - val_loss: 2.5728 - val_accuracy: 0.1154\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5220 - accuracy: 0.2051 - val_loss: 2.5673 - val_accuracy: 0.1154\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5148 - accuracy: 0.2051 - val_loss: 2.5627 - val_accuracy: 0.1154\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5080 - accuracy: 0.2051 - val_loss: 2.5587 - val_accuracy: 0.1538\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.5014 - accuracy: 0.1795 - val_loss: 2.5549 - val_accuracy: 0.1154\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4946 - accuracy: 0.1795 - val_loss: 2.5512 - val_accuracy: 0.1154\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4879 - accuracy: 0.1795 - val_loss: 2.5473 - val_accuracy: 0.1154\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4812 - accuracy: 0.1795 - val_loss: 2.5432 - val_accuracy: 0.1154\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4743 - accuracy: 0.2051 - val_loss: 2.5394 - val_accuracy: 0.1154\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4673 - accuracy: 0.2179 - val_loss: 2.5354 - val_accuracy: 0.1154\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4603 - accuracy: 0.2692 - val_loss: 2.5309 - val_accuracy: 0.1154\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4532 - accuracy: 0.2692 - val_loss: 2.5261 - val_accuracy: 0.1154\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4458 - accuracy: 0.2821 - val_loss: 2.5212 - val_accuracy: 0.1154\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4378 - accuracy: 0.2949 - val_loss: 2.5163 - val_accuracy: 0.1154\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4298 - accuracy: 0.3077 - val_loss: 2.5111 - val_accuracy: 0.1154\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4215 - accuracy: 0.3077 - val_loss: 2.5055 - val_accuracy: 0.1154\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 2.4131 - accuracy: 0.3205 - val_loss: 2.5000 - val_accuracy: 0.1538\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.4045 - accuracy: 0.3333 - val_loss: 2.4945 - val_accuracy: 0.2308\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3956 - accuracy: 0.3333 - val_loss: 2.4887 - val_accuracy: 0.1538\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3865 - accuracy: 0.3333 - val_loss: 2.4828 - val_accuracy: 0.1923\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3770 - accuracy: 0.3077 - val_loss: 2.4767 - val_accuracy: 0.1538\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3672 - accuracy: 0.3077 - val_loss: 2.4704 - val_accuracy: 0.1538\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3570 - accuracy: 0.3205 - val_loss: 2.4639 - val_accuracy: 0.1538\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.3465 - accuracy: 0.3333 - val_loss: 2.4569 - val_accuracy: 0.1538\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3355 - accuracy: 0.3590 - val_loss: 2.4498 - val_accuracy: 0.1538\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3242 - accuracy: 0.3590 - val_loss: 2.4430 - val_accuracy: 0.1538\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3127 - accuracy: 0.3590 - val_loss: 2.4355 - val_accuracy: 0.1538\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3007 - accuracy: 0.3590 - val_loss: 2.4277 - val_accuracy: 0.1538\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2880 - accuracy: 0.3718 - val_loss: 2.4195 - val_accuracy: 0.1538\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2750 - accuracy: 0.3718 - val_loss: 2.4107 - val_accuracy: 0.1538\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2612 - accuracy: 0.3718 - val_loss: 2.4019 - val_accuracy: 0.1538\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.2469 - accuracy: 0.3974 - val_loss: 2.3935 - val_accuracy: 0.1538\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2321 - accuracy: 0.4103 - val_loss: 2.3844 - val_accuracy: 0.1923\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2167 - accuracy: 0.4103 - val_loss: 2.3749 - val_accuracy: 0.1923\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.2007 - accuracy: 0.4615 - val_loss: 2.3652 - val_accuracy: 0.1923\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.1843 - accuracy: 0.4615 - val_loss: 2.3551 - val_accuracy: 0.1923\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.1674 - accuracy: 0.5000 - val_loss: 2.3449 - val_accuracy: 0.1923\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.1499 - accuracy: 0.5128 - val_loss: 2.3338 - val_accuracy: 0.1923\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.1316 - accuracy: 0.5128 - val_loss: 2.3222 - val_accuracy: 0.1923\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.1125 - accuracy: 0.5128 - val_loss: 2.3102 - val_accuracy: 0.1923\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0926 - accuracy: 0.5128 - val_loss: 2.2976 - val_accuracy: 0.1923\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0715 - accuracy: 0.5128 - val_loss: 2.2843 - val_accuracy: 0.1923\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 2.0496 - accuracy: 0.5513 - val_loss: 2.2707 - val_accuracy: 0.2308\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0271 - accuracy: 0.5513 - val_loss: 2.2570 - val_accuracy: 0.3077\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0043 - accuracy: 0.5769 - val_loss: 2.2423 - val_accuracy: 0.3077\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.9806 - accuracy: 0.5769 - val_loss: 2.2270 - val_accuracy: 0.3077\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.9561 - accuracy: 0.6026 - val_loss: 2.2113 - val_accuracy: 0.3077\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.9311 - accuracy: 0.6667 - val_loss: 2.1953 - val_accuracy: 0.3077\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.9056 - accuracy: 0.7051 - val_loss: 2.1790 - val_accuracy: 0.3077\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.8796 - accuracy: 0.7051 - val_loss: 2.1620 - val_accuracy: 0.3077\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8531 - accuracy: 0.7051 - val_loss: 2.1452 - val_accuracy: 0.3462\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8264 - accuracy: 0.7179 - val_loss: 2.1273 - val_accuracy: 0.3846\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7989 - accuracy: 0.7564 - val_loss: 2.1106 - val_accuracy: 0.3846\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7716 - accuracy: 0.7564 - val_loss: 2.0931 - val_accuracy: 0.3846\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.7436 - accuracy: 0.7436 - val_loss: 2.0757 - val_accuracy: 0.3846\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7152 - accuracy: 0.7692 - val_loss: 2.0585 - val_accuracy: 0.3846\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6863 - accuracy: 0.7564 - val_loss: 2.0410 - val_accuracy: 0.3846\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6573 - accuracy: 0.7564 - val_loss: 2.0233 - val_accuracy: 0.3846\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.6279 - accuracy: 0.7564 - val_loss: 2.0062 - val_accuracy: 0.4231\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.5986 - accuracy: 0.7564 - val_loss: 1.9880 - val_accuracy: 0.4615\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5687 - accuracy: 0.7564 - val_loss: 1.9703 - val_accuracy: 0.4615\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5388 - accuracy: 0.7692 - val_loss: 1.9524 - val_accuracy: 0.4615\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5090 - accuracy: 0.7692 - val_loss: 1.9332 - val_accuracy: 0.4615\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.4791 - accuracy: 0.7692 - val_loss: 1.9150 - val_accuracy: 0.4615\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4492 - accuracy: 0.7821 - val_loss: 1.8975 - val_accuracy: 0.4615\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4195 - accuracy: 0.7821 - val_loss: 1.8793 - val_accuracy: 0.4615\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.3901 - accuracy: 0.8205 - val_loss: 1.8615 - val_accuracy: 0.4615\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3605 - accuracy: 0.8205 - val_loss: 1.8440 - val_accuracy: 0.4615\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3313 - accuracy: 0.8205 - val_loss: 1.8261 - val_accuracy: 0.5385\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3024 - accuracy: 0.8205 - val_loss: 1.8084 - val_accuracy: 0.5385\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2735 - accuracy: 0.8333 - val_loss: 1.7924 - val_accuracy: 0.5385\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2450 - accuracy: 0.8462 - val_loss: 1.7769 - val_accuracy: 0.5385\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.2170 - accuracy: 0.8462 - val_loss: 1.7602 - val_accuracy: 0.5385\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1891 - accuracy: 0.8462 - val_loss: 1.7442 - val_accuracy: 0.5385\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.1617 - accuracy: 0.8462 - val_loss: 1.7284 - val_accuracy: 0.5769\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1349 - accuracy: 0.8462 - val_loss: 1.7133 - val_accuracy: 0.5769\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1085 - accuracy: 0.8718 - val_loss: 1.6995 - val_accuracy: 0.5769\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0825 - accuracy: 0.8718 - val_loss: 1.6856 - val_accuracy: 0.5769\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0570 - accuracy: 0.8718 - val_loss: 1.6727 - val_accuracy: 0.6154\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0320 - accuracy: 0.8718 - val_loss: 1.6603 - val_accuracy: 0.6154\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0074 - accuracy: 0.8718 - val_loss: 1.6485 - val_accuracy: 0.6154\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9834 - accuracy: 0.8718 - val_loss: 1.6362 - val_accuracy: 0.6154\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9599 - accuracy: 0.8718 - val_loss: 1.6235 - val_accuracy: 0.6154\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.9367 - accuracy: 0.8718 - val_loss: 1.6126 - val_accuracy: 0.6154\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9140 - accuracy: 0.8718 - val_loss: 1.6025 - val_accuracy: 0.6154\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8921 - accuracy: 0.8718 - val_loss: 1.5909 - val_accuracy: 0.6154\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8701 - accuracy: 0.8718 - val_loss: 1.5811 - val_accuracy: 0.6154\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8488 - accuracy: 0.8846 - val_loss: 1.5713 - val_accuracy: 0.6154\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8281 - accuracy: 0.8846 - val_loss: 1.5608 - val_accuracy: 0.6154\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.8077 - accuracy: 0.8846 - val_loss: 1.5501 - val_accuracy: 0.6154\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7876 - accuracy: 0.8846 - val_loss: 1.5397 - val_accuracy: 0.6154\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7682 - accuracy: 0.8974 - val_loss: 1.5302 - val_accuracy: 0.6154\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7492 - accuracy: 0.8974 - val_loss: 1.5226 - val_accuracy: 0.6538\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7307 - accuracy: 0.9231 - val_loss: 1.5150 - val_accuracy: 0.6538\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7126 - accuracy: 0.9231 - val_loss: 1.5056 - val_accuracy: 0.6538\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6948 - accuracy: 0.9231 - val_loss: 1.4956 - val_accuracy: 0.6538\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6776 - accuracy: 0.9359 - val_loss: 1.4863 - val_accuracy: 0.6538\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6610 - accuracy: 0.9359 - val_loss: 1.4787 - val_accuracy: 0.6538\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6447 - accuracy: 0.9487 - val_loss: 1.4734 - val_accuracy: 0.6538\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6289 - accuracy: 0.9487 - val_loss: 1.4675 - val_accuracy: 0.6538\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6136 - accuracy: 0.9487 - val_loss: 1.4608 - val_accuracy: 0.6538\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5988 - accuracy: 0.9615 - val_loss: 1.4530 - val_accuracy: 0.6538\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5843 - accuracy: 0.9615 - val_loss: 1.4464 - val_accuracy: 0.6538\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5701 - accuracy: 0.9615 - val_loss: 1.4410 - val_accuracy: 0.6538\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5565 - accuracy: 0.9615 - val_loss: 1.4353 - val_accuracy: 0.6538\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5434 - accuracy: 0.9615 - val_loss: 1.4291 - val_accuracy: 0.6538\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.9615 - val_loss: 1.4244 - val_accuracy: 0.6538\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5182 - accuracy: 0.9615 - val_loss: 1.4198 - val_accuracy: 0.6538\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5062 - accuracy: 0.9615 - val_loss: 1.4154 - val_accuracy: 0.6538\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4944 - accuracy: 0.9615 - val_loss: 1.4124 - val_accuracy: 0.6538\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4831 - accuracy: 0.9615 - val_loss: 1.4088 - val_accuracy: 0.6538\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4720 - accuracy: 0.9615 - val_loss: 1.4051 - val_accuracy: 0.6538\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4612 - accuracy: 0.9615 - val_loss: 1.4022 - val_accuracy: 0.6538\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4508 - accuracy: 0.9615 - val_loss: 1.3986 - val_accuracy: 0.6538\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4409 - accuracy: 0.9615 - val_loss: 1.3955 - val_accuracy: 0.6538\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4311 - accuracy: 0.9615 - val_loss: 1.3937 - val_accuracy: 0.6538\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4215 - accuracy: 0.9615 - val_loss: 1.3921 - val_accuracy: 0.6538\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4124 - accuracy: 0.9615 - val_loss: 1.3890 - val_accuracy: 0.6538\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4034 - accuracy: 0.9615 - val_loss: 1.3862 - val_accuracy: 0.6538\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3948 - accuracy: 0.9615 - val_loss: 1.3837 - val_accuracy: 0.6538\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3864 - accuracy: 0.9615 - val_loss: 1.3815 - val_accuracy: 0.6538\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3783 - accuracy: 0.9615 - val_loss: 1.3803 - val_accuracy: 0.6538\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3704 - accuracy: 0.9615 - val_loss: 1.3802 - val_accuracy: 0.6538\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3629 - accuracy: 0.9615 - val_loss: 1.3792 - val_accuracy: 0.6538\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3555 - accuracy: 0.9615 - val_loss: 1.3781 - val_accuracy: 0.6538\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3485 - accuracy: 0.9615 - val_loss: 1.3771 - val_accuracy: 0.6538\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3416 - accuracy: 0.9615 - val_loss: 1.3770 - val_accuracy: 0.6538\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3348 - accuracy: 0.9615 - val_loss: 1.3776 - val_accuracy: 0.6538\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3283 - accuracy: 0.9615 - val_loss: 1.3772 - val_accuracy: 0.6538\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3219 - accuracy: 0.9615 - val_loss: 1.3762 - val_accuracy: 0.6538\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3157 - accuracy: 0.9615 - val_loss: 1.3763 - val_accuracy: 0.6538\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3097 - accuracy: 0.9615 - val_loss: 1.3769 - val_accuracy: 0.6538\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3040 - accuracy: 0.9615 - val_loss: 1.3777 - val_accuracy: 0.6538\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2984 - accuracy: 0.9615 - val_loss: 1.3774 - val_accuracy: 0.6538\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2928 - accuracy: 0.9615 - val_loss: 1.3764 - val_accuracy: 0.6538\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2875 - accuracy: 0.9615 - val_loss: 1.3771 - val_accuracy: 0.6538\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2823 - accuracy: 0.9615 - val_loss: 1.3784 - val_accuracy: 0.6538\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2772 - accuracy: 0.9615 - val_loss: 1.3796 - val_accuracy: 0.6538\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2723 - accuracy: 0.9615 - val_loss: 1.3805 - val_accuracy: 0.6538\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2675 - accuracy: 0.9615 - val_loss: 1.3816 - val_accuracy: 0.6923\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2629 - accuracy: 0.9615 - val_loss: 1.3823 - val_accuracy: 0.6923\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2585 - accuracy: 0.9615 - val_loss: 1.3830 - val_accuracy: 0.6923\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2541 - accuracy: 0.9615 - val_loss: 1.3847 - val_accuracy: 0.6923\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2499 - accuracy: 0.9615 - val_loss: 1.3850 - val_accuracy: 0.6923\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2457 - accuracy: 0.9615 - val_loss: 1.3847 - val_accuracy: 0.6923\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2416 - accuracy: 0.9615 - val_loss: 1.3859 - val_accuracy: 0.6923\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2377 - accuracy: 0.9615 - val_loss: 1.3873 - val_accuracy: 0.6923\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2338 - accuracy: 0.9615 - val_loss: 1.3878 - val_accuracy: 0.6923\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2301 - accuracy: 0.9615 - val_loss: 1.3885 - val_accuracy: 0.6923\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2264 - accuracy: 0.9615 - val_loss: 1.3893 - val_accuracy: 0.6923\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2228 - accuracy: 0.9615 - val_loss: 1.3909 - val_accuracy: 0.6923\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2194 - accuracy: 0.9615 - val_loss: 1.3927 - val_accuracy: 0.6923\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2159 - accuracy: 0.9615 - val_loss: 1.3940 - val_accuracy: 0.6923\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2125 - accuracy: 0.9615 - val_loss: 1.3956 - val_accuracy: 0.6923\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2093 - accuracy: 0.9615 - val_loss: 1.3964 - val_accuracy: 0.6923\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2060 - accuracy: 0.9615 - val_loss: 1.3965 - val_accuracy: 0.6923\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2029 - accuracy: 0.9615 - val_loss: 1.3976 - val_accuracy: 0.6923\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1999 - accuracy: 0.9615 - val_loss: 1.3980 - val_accuracy: 0.6923\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1967 - accuracy: 0.9615 - val_loss: 1.3983 - val_accuracy: 0.6923\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1938 - accuracy: 0.9615 - val_loss: 1.4000 - val_accuracy: 0.6923\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1909 - accuracy: 0.9615 - val_loss: 1.4027 - val_accuracy: 0.6923\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1881 - accuracy: 0.9615 - val_loss: 1.4044 - val_accuracy: 0.6923\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1854 - accuracy: 0.9615 - val_loss: 1.4051 - val_accuracy: 0.6923\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1827 - accuracy: 0.9615 - val_loss: 1.4066 - val_accuracy: 0.6923\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1801 - accuracy: 0.9615 - val_loss: 1.4094 - val_accuracy: 0.6923\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1777 - accuracy: 0.9615 - val_loss: 1.4109 - val_accuracy: 0.6923\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1752 - accuracy: 0.9615 - val_loss: 1.4109 - val_accuracy: 0.6923\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1727 - accuracy: 0.9615 - val_loss: 1.4113 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1703 - accuracy: 0.9615 - val_loss: 1.4132 - val_accuracy: 0.6923\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1679 - accuracy: 0.9615 - val_loss: 1.4153 - val_accuracy: 0.6923\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1657 - accuracy: 0.9615 - val_loss: 1.4173 - val_accuracy: 0.6923\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1635 - accuracy: 0.9615 - val_loss: 1.4171 - val_accuracy: 0.6923\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1613 - accuracy: 0.9615 - val_loss: 1.4176 - val_accuracy: 0.6923\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1591 - accuracy: 0.9615 - val_loss: 1.4187 - val_accuracy: 0.6923\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1570 - accuracy: 0.9615 - val_loss: 1.4202 - val_accuracy: 0.6923\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1550 - accuracy: 0.9615 - val_loss: 1.4220 - val_accuracy: 0.6923\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1530 - accuracy: 0.9615 - val_loss: 1.4231 - val_accuracy: 0.6923\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1511 - accuracy: 0.9615 - val_loss: 1.4247 - val_accuracy: 0.6923\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1493 - accuracy: 0.9615 - val_loss: 1.4267 - val_accuracy: 0.6923\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1474 - accuracy: 0.9615 - val_loss: 1.4272 - val_accuracy: 0.6923\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1455 - accuracy: 0.9744 - val_loss: 1.4279 - val_accuracy: 0.6923\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1437 - accuracy: 0.9744 - val_loss: 1.4293 - val_accuracy: 0.6923\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1419 - accuracy: 0.9744 - val_loss: 1.4296 - val_accuracy: 0.6923\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1401 - accuracy: 0.9744 - val_loss: 1.4310 - val_accuracy: 0.6923\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1384 - accuracy: 0.9744 - val_loss: 1.4330 - val_accuracy: 0.6923\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1367 - accuracy: 0.9744 - val_loss: 1.4338 - val_accuracy: 0.6923\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1351 - accuracy: 0.9744 - val_loss: 1.4348 - val_accuracy: 0.6923\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1335 - accuracy: 0.9744 - val_loss: 1.4367 - val_accuracy: 0.6923\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1318 - accuracy: 0.9744 - val_loss: 1.4381 - val_accuracy: 0.6923\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.9744 - val_loss: 1.4396 - val_accuracy: 0.6923\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.1287 - accuracy: 0.9744 - val_loss: 1.4402 - val_accuracy: 0.6923\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1273 - accuracy: 0.9744 - val_loss: 1.4416 - val_accuracy: 0.6923\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1257 - accuracy: 0.9744 - val_loss: 1.4425 - val_accuracy: 0.6923\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1243 - accuracy: 0.9744 - val_loss: 1.4443 - val_accuracy: 0.6923\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(30)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(30)\n",
    "\n",
    "#history = conv_model.fit(x = X_train, y = Y_train, validation_data = (X_test, Y_test), epochs=500, batch_size=200)\n",
    "history = conv_model.fit(train_dataset, epochs=200, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f67ac95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.607323169708252,\n",
       "  2.586627960205078,\n",
       "  2.5709002017974854,\n",
       "  2.5586960315704346,\n",
       "  2.5482516288757324,\n",
       "  2.5385029315948486,\n",
       "  2.5298590660095215,\n",
       "  2.522015333175659,\n",
       "  2.514770030975342,\n",
       "  2.507982015609741,\n",
       "  2.5013797283172607,\n",
       "  2.4946229457855225,\n",
       "  2.4879064559936523,\n",
       "  2.4811925888061523,\n",
       "  2.4743008613586426,\n",
       "  2.4673008918762207,\n",
       "  2.4602901935577393,\n",
       "  2.4532086849212646,\n",
       "  2.44575572013855,\n",
       "  2.4378254413604736,\n",
       "  2.429818630218506,\n",
       "  2.421543598175049,\n",
       "  2.4131290912628174,\n",
       "  2.4044668674468994,\n",
       "  2.395587921142578,\n",
       "  2.386509656906128,\n",
       "  2.3769938945770264,\n",
       "  2.3671562671661377,\n",
       "  2.3570408821105957,\n",
       "  2.3465046882629395,\n",
       "  2.3355355262756348,\n",
       "  2.3242263793945312,\n",
       "  2.312734365463257,\n",
       "  2.3006911277770996,\n",
       "  2.287992000579834,\n",
       "  2.274951934814453,\n",
       "  2.261186361312866,\n",
       "  2.2468926906585693,\n",
       "  2.2321434020996094,\n",
       "  2.216702699661255,\n",
       "  2.200737714767456,\n",
       "  2.184330940246582,\n",
       "  2.1673991680145264,\n",
       "  2.149909496307373,\n",
       "  2.1316189765930176,\n",
       "  2.112478494644165,\n",
       "  2.092554807662964,\n",
       "  2.071533203125,\n",
       "  2.0496468544006348,\n",
       "  2.0270936489105225,\n",
       "  2.0043084621429443,\n",
       "  1.9805654287338257,\n",
       "  1.9561495780944824,\n",
       "  1.9311434030532837,\n",
       "  1.9055520296096802,\n",
       "  1.8796075582504272,\n",
       "  1.8531345129013062,\n",
       "  1.8264151811599731,\n",
       "  1.7988736629486084,\n",
       "  1.7716219425201416,\n",
       "  1.7435742616653442,\n",
       "  1.7151764631271362,\n",
       "  1.6863210201263428,\n",
       "  1.6573412418365479,\n",
       "  1.6279261112213135,\n",
       "  1.5986206531524658,\n",
       "  1.568663477897644,\n",
       "  1.538849115371704,\n",
       "  1.5090171098709106,\n",
       "  1.4791126251220703,\n",
       "  1.449224591255188,\n",
       "  1.419513463973999,\n",
       "  1.390078067779541,\n",
       "  1.360528826713562,\n",
       "  1.331344485282898,\n",
       "  1.302371859550476,\n",
       "  1.2735483646392822,\n",
       "  1.2450400590896606,\n",
       "  1.2169619798660278,\n",
       "  1.1891229152679443,\n",
       "  1.1617412567138672,\n",
       "  1.1348960399627686,\n",
       "  1.1085258722305298,\n",
       "  1.0825083255767822,\n",
       "  1.0569936037063599,\n",
       "  1.0319761037826538,\n",
       "  1.007442593574524,\n",
       "  0.9834274053573608,\n",
       "  0.9599264860153198,\n",
       "  0.9366539120674133,\n",
       "  0.9140373468399048,\n",
       "  0.8920736312866211,\n",
       "  0.8700515627861023,\n",
       "  0.8488203883171082,\n",
       "  0.828073263168335,\n",
       "  0.8076816201210022,\n",
       "  0.7876195907592773,\n",
       "  0.76817786693573,\n",
       "  0.7491869926452637,\n",
       "  0.7307345271110535,\n",
       "  0.7125875949859619,\n",
       "  0.6947631239891052,\n",
       "  0.6775566339492798,\n",
       "  0.6609710454940796,\n",
       "  0.6446695327758789,\n",
       "  0.6288878321647644,\n",
       "  0.6136220097541809,\n",
       "  0.5988268256187439,\n",
       "  0.5843009352684021,\n",
       "  0.570145308971405,\n",
       "  0.5565370321273804,\n",
       "  0.5434269309043884,\n",
       "  0.5305576920509338,\n",
       "  0.5181946754455566,\n",
       "  0.5061609148979187,\n",
       "  0.4944055378437042,\n",
       "  0.4830573499202728,\n",
       "  0.47196143865585327,\n",
       "  0.4612409770488739,\n",
       "  0.45084115862846375,\n",
       "  0.4408726394176483,\n",
       "  0.43105995655059814,\n",
       "  0.4215448200702667,\n",
       "  0.41236555576324463,\n",
       "  0.40337732434272766,\n",
       "  0.39475181698799133,\n",
       "  0.3864190876483917,\n",
       "  0.3783450126647949,\n",
       "  0.37042173743247986,\n",
       "  0.3629099726676941,\n",
       "  0.35553839802742004,\n",
       "  0.3484816551208496,\n",
       "  0.3415738046169281,\n",
       "  0.3348032832145691,\n",
       "  0.32829293608665466,\n",
       "  0.3218878507614136,\n",
       "  0.3156989514827728,\n",
       "  0.3097103238105774,\n",
       "  0.30397164821624756,\n",
       "  0.29835498332977295,\n",
       "  0.2927919924259186,\n",
       "  0.2874792814254761,\n",
       "  0.2822759747505188,\n",
       "  0.2772293984889984,\n",
       "  0.27226224541664124,\n",
       "  0.26751822233200073,\n",
       "  0.2629132866859436,\n",
       "  0.25846126675605774,\n",
       "  0.2541079521179199,\n",
       "  0.24993006885051727,\n",
       "  0.2457355409860611,\n",
       "  0.24164938926696777,\n",
       "  0.23770007491111755,\n",
       "  0.23383663594722748,\n",
       "  0.2300986796617508,\n",
       "  0.2264304757118225,\n",
       "  0.22281058132648468,\n",
       "  0.21941371262073517,\n",
       "  0.21589834988117218,\n",
       "  0.21250130236148834,\n",
       "  0.2093094140291214,\n",
       "  0.20602042973041534,\n",
       "  0.2029116004705429,\n",
       "  0.19987212121486664,\n",
       "  0.1967458426952362,\n",
       "  0.19378972053527832,\n",
       "  0.190939262509346,\n",
       "  0.1881302446126938,\n",
       "  0.1854304075241089,\n",
       "  0.18269973993301392,\n",
       "  0.18012215197086334,\n",
       "  0.17766684293746948,\n",
       "  0.17521701753139496,\n",
       "  0.17269793152809143,\n",
       "  0.17028380930423737,\n",
       "  0.16791905462741852,\n",
       "  0.16569383442401886,\n",
       "  0.16351966559886932,\n",
       "  0.16128264367580414,\n",
       "  0.15911173820495605,\n",
       "  0.15704266726970673,\n",
       "  0.15504036843776703,\n",
       "  0.15303124487400055,\n",
       "  0.15109460055828094,\n",
       "  0.14926791191101074,\n",
       "  0.14738444983959198,\n",
       "  0.145501047372818,\n",
       "  0.14367546141147614,\n",
       "  0.14186257123947144,\n",
       "  0.14008891582489014,\n",
       "  0.1384029984474182,\n",
       "  0.13669933378696442,\n",
       "  0.13509003818035126,\n",
       "  0.13345427811145782,\n",
       "  0.13184118270874023,\n",
       "  0.13028165698051453,\n",
       "  0.12871840596199036,\n",
       "  0.12725679576396942,\n",
       "  0.12572892010211945,\n",
       "  0.1242709532380104],\n",
       " 'accuracy': [0.07692307978868484,\n",
       "  0.07692307978868484,\n",
       "  0.10256410390138626,\n",
       "  0.11538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1666666716337204,\n",
       "  0.1794871836900711,\n",
       "  0.20512820780277252,\n",
       "  0.20512820780277252,\n",
       "  0.20512820780277252,\n",
       "  0.1794871836900711,\n",
       "  0.1794871836900711,\n",
       "  0.1794871836900711,\n",
       "  0.1794871836900711,\n",
       "  0.20512820780277252,\n",
       "  0.21794871985912323,\n",
       "  0.26923078298568726,\n",
       "  0.26923078298568726,\n",
       "  0.28205129504203796,\n",
       "  0.29487180709838867,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3205128312110901,\n",
       "  0.3333333432674408,\n",
       "  0.3333333432674408,\n",
       "  0.3333333432674408,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3205128312110901,\n",
       "  0.3333333432674408,\n",
       "  0.3589743673801422,\n",
       "  0.3589743673801422,\n",
       "  0.3589743673801422,\n",
       "  0.3589743673801422,\n",
       "  0.3717948794364929,\n",
       "  0.3717948794364929,\n",
       "  0.3717948794364929,\n",
       "  0.39743590354919434,\n",
       "  0.41025641560554504,\n",
       "  0.41025641560554504,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.5,\n",
       "  0.5128205418586731,\n",
       "  0.5128205418586731,\n",
       "  0.5128205418586731,\n",
       "  0.5128205418586731,\n",
       "  0.5128205418586731,\n",
       "  0.5512820482254028,\n",
       "  0.5512820482254028,\n",
       "  0.5769230723381042,\n",
       "  0.5769230723381042,\n",
       "  0.6025640964508057,\n",
       "  0.6666666865348816,\n",
       "  0.7051281929016113,\n",
       "  0.7051281929016113,\n",
       "  0.7051281929016113,\n",
       "  0.7179487347602844,\n",
       "  0.7564102411270142,\n",
       "  0.7564102411270142,\n",
       "  0.7435897588729858,\n",
       "  0.7692307829856873,\n",
       "  0.7564102411270142,\n",
       "  0.7564102411270142,\n",
       "  0.7564102411270142,\n",
       "  0.7564102411270142,\n",
       "  0.7564102411270142,\n",
       "  0.7692307829856873,\n",
       "  0.7692307829856873,\n",
       "  0.7692307829856873,\n",
       "  0.7820512652397156,\n",
       "  0.7820512652397156,\n",
       "  0.8205128312110901,\n",
       "  0.8205128312110901,\n",
       "  0.8205128312110901,\n",
       "  0.8205128312110901,\n",
       "  0.8333333134651184,\n",
       "  0.8461538553237915,\n",
       "  0.8461538553237915,\n",
       "  0.8461538553237915,\n",
       "  0.8461538553237915,\n",
       "  0.8461538553237915,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8717948794364929,\n",
       "  0.8846153616905212,\n",
       "  0.8846153616905212,\n",
       "  0.8846153616905212,\n",
       "  0.8846153616905212,\n",
       "  0.8974359035491943,\n",
       "  0.8974359035491943,\n",
       "  0.9230769276618958,\n",
       "  0.9230769276618958,\n",
       "  0.9230769276618958,\n",
       "  0.9358974099159241,\n",
       "  0.9358974099159241,\n",
       "  0.9487179517745972,\n",
       "  0.9487179517745972,\n",
       "  0.9487179517745972,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9615384340286255,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986,\n",
       "  0.9743589758872986],\n",
       " 'val_loss': [2.6305272579193115,\n",
       "  2.616629123687744,\n",
       "  2.60453462600708,\n",
       "  2.5945751667022705,\n",
       "  2.586486339569092,\n",
       "  2.5793497562408447,\n",
       "  2.5727529525756836,\n",
       "  2.567258596420288,\n",
       "  2.5627336502075195,\n",
       "  2.558661937713623,\n",
       "  2.55493426322937,\n",
       "  2.551241397857666,\n",
       "  2.5472934246063232,\n",
       "  2.5432002544403076,\n",
       "  2.53944730758667,\n",
       "  2.5353989601135254,\n",
       "  2.530918598175049,\n",
       "  2.5261027812957764,\n",
       "  2.521240234375,\n",
       "  2.516298532485962,\n",
       "  2.5111196041107178,\n",
       "  2.5055150985717773,\n",
       "  2.499990940093994,\n",
       "  2.494520902633667,\n",
       "  2.4887442588806152,\n",
       "  2.4828341007232666,\n",
       "  2.476681709289551,\n",
       "  2.470427989959717,\n",
       "  2.4639017581939697,\n",
       "  2.4568636417388916,\n",
       "  2.4497783184051514,\n",
       "  2.442971706390381,\n",
       "  2.435479164123535,\n",
       "  2.4276630878448486,\n",
       "  2.4195408821105957,\n",
       "  2.4106898307800293,\n",
       "  2.401942253112793,\n",
       "  2.3934760093688965,\n",
       "  2.3843746185302734,\n",
       "  2.3748888969421387,\n",
       "  2.36519193649292,\n",
       "  2.3551383018493652,\n",
       "  2.3449079990386963,\n",
       "  2.333791494369507,\n",
       "  2.322181224822998,\n",
       "  2.310232639312744,\n",
       "  2.2975504398345947,\n",
       "  2.284257650375366,\n",
       "  2.270693063735962,\n",
       "  2.2569668292999268,\n",
       "  2.242288112640381,\n",
       "  2.227001667022705,\n",
       "  2.211259603500366,\n",
       "  2.1953186988830566,\n",
       "  2.178988456726074,\n",
       "  2.1620099544525146,\n",
       "  2.1451573371887207,\n",
       "  2.1273083686828613,\n",
       "  2.1106107234954834,\n",
       "  2.0931200981140137,\n",
       "  2.0756614208221436,\n",
       "  2.0585250854492188,\n",
       "  2.041013240814209,\n",
       "  2.0232865810394287,\n",
       "  2.0062191486358643,\n",
       "  1.9879868030548096,\n",
       "  1.9703336954116821,\n",
       "  1.9523533582687378,\n",
       "  1.933204174041748,\n",
       "  1.9150115251541138,\n",
       "  1.8975181579589844,\n",
       "  1.8792788982391357,\n",
       "  1.8614579439163208,\n",
       "  1.843994140625,\n",
       "  1.8260893821716309,\n",
       "  1.80836820602417,\n",
       "  1.7924485206604004,\n",
       "  1.776885986328125,\n",
       "  1.7601503133773804,\n",
       "  1.7441506385803223,\n",
       "  1.7283746004104614,\n",
       "  1.7133495807647705,\n",
       "  1.699454665184021,\n",
       "  1.6856223344802856,\n",
       "  1.6726791858673096,\n",
       "  1.6603354215621948,\n",
       "  1.6484873294830322,\n",
       "  1.6361809968948364,\n",
       "  1.6235333681106567,\n",
       "  1.6126068830490112,\n",
       "  1.6024729013442993,\n",
       "  1.5908615589141846,\n",
       "  1.5810647010803223,\n",
       "  1.5713403224945068,\n",
       "  1.5607860088348389,\n",
       "  1.5500881671905518,\n",
       "  1.5397275686264038,\n",
       "  1.5301837921142578,\n",
       "  1.5226423740386963,\n",
       "  1.5149625539779663,\n",
       "  1.5055677890777588,\n",
       "  1.495635747909546,\n",
       "  1.4862990379333496,\n",
       "  1.4787477254867554,\n",
       "  1.4733507633209229,\n",
       "  1.4674937725067139,\n",
       "  1.4608190059661865,\n",
       "  1.4530326128005981,\n",
       "  1.446366548538208,\n",
       "  1.4409828186035156,\n",
       "  1.4353487491607666,\n",
       "  1.4290705919265747,\n",
       "  1.4244104623794556,\n",
       "  1.4197853803634644,\n",
       "  1.4153937101364136,\n",
       "  1.4123594760894775,\n",
       "  1.4087504148483276,\n",
       "  1.405057668685913,\n",
       "  1.4021512269973755,\n",
       "  1.398645281791687,\n",
       "  1.3954867124557495,\n",
       "  1.3937283754348755,\n",
       "  1.3921470642089844,\n",
       "  1.3889920711517334,\n",
       "  1.3862125873565674,\n",
       "  1.383699655532837,\n",
       "  1.3815237283706665,\n",
       "  1.3803292512893677,\n",
       "  1.3801642656326294,\n",
       "  1.3792067766189575,\n",
       "  1.3780592679977417,\n",
       "  1.3770596981048584,\n",
       "  1.37701416015625,\n",
       "  1.3775899410247803,\n",
       "  1.3772155046463013,\n",
       "  1.3762098550796509,\n",
       "  1.3762849569320679,\n",
       "  1.3769476413726807,\n",
       "  1.3777304887771606,\n",
       "  1.3774223327636719,\n",
       "  1.376386046409607,\n",
       "  1.3771018981933594,\n",
       "  1.378436803817749,\n",
       "  1.379555344581604,\n",
       "  1.380500316619873,\n",
       "  1.381565809249878,\n",
       "  1.3823299407958984,\n",
       "  1.3830053806304932,\n",
       "  1.384730577468872,\n",
       "  1.3850040435791016,\n",
       "  1.3847224712371826,\n",
       "  1.3859217166900635,\n",
       "  1.387311339378357,\n",
       "  1.3877894878387451,\n",
       "  1.3885213136672974,\n",
       "  1.389256238937378,\n",
       "  1.3908843994140625,\n",
       "  1.3926582336425781,\n",
       "  1.394013524055481,\n",
       "  1.3956291675567627,\n",
       "  1.3964170217514038,\n",
       "  1.396453857421875,\n",
       "  1.3976010084152222,\n",
       "  1.3979594707489014,\n",
       "  1.398277759552002,\n",
       "  1.3999617099761963,\n",
       "  1.4027018547058105,\n",
       "  1.404407024383545,\n",
       "  1.4051170349121094,\n",
       "  1.40657377243042,\n",
       "  1.4093762636184692,\n",
       "  1.4108906984329224,\n",
       "  1.4109216928482056,\n",
       "  1.4112826585769653,\n",
       "  1.4132330417633057,\n",
       "  1.4153093099594116,\n",
       "  1.4172619581222534,\n",
       "  1.4171477556228638,\n",
       "  1.41762375831604,\n",
       "  1.4186826944351196,\n",
       "  1.4202477931976318,\n",
       "  1.4219896793365479,\n",
       "  1.4230786561965942,\n",
       "  1.4247257709503174,\n",
       "  1.426710605621338,\n",
       "  1.4272003173828125,\n",
       "  1.4279264211654663,\n",
       "  1.4293131828308105,\n",
       "  1.4296228885650635,\n",
       "  1.4310357570648193,\n",
       "  1.4330073595046997,\n",
       "  1.4337750673294067,\n",
       "  1.434821367263794,\n",
       "  1.4367436170578003,\n",
       "  1.4381256103515625,\n",
       "  1.439583420753479,\n",
       "  1.4402213096618652,\n",
       "  1.441611409187317,\n",
       "  1.4425251483917236,\n",
       "  1.4443435668945312],\n",
       " 'val_accuracy': [0.07692307978868484,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.11538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.23076923191547394,\n",
       "  0.1538461595773697,\n",
       "  0.19230769574642181,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.1538461595773697,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.19230769574642181,\n",
       "  0.23076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3076923191547394,\n",
       "  0.3461538553237915,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.38461539149284363,\n",
       "  0.42307692766189575,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.4615384638309479,\n",
       "  0.5384615659713745,\n",
       "  0.5384615659713745,\n",
       "  0.5384615659713745,\n",
       "  0.5384615659713745,\n",
       "  0.5384615659713745,\n",
       "  0.5384615659713745,\n",
       "  0.5769230723381042,\n",
       "  0.5769230723381042,\n",
       "  0.5769230723381042,\n",
       "  0.5769230723381042,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6153846383094788,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.6538461446762085,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583,\n",
       "  0.692307710647583]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f388756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The history.history[\"loss\"] entry is a dictionary with as many values as epochs that the\n",
    "# model was trained on. \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig(\"D:\\\\BLE_RSSI_dataset\\\\accuracy.jpeg\")\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig(\"D:\\\\BLE_RSSI_dataset\\\\loss.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bc69332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c46bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1,1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Second component of main path (3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding ='same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ## Third component of main path (2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) \n",
    "    \n",
    "    ## Final step: Add shortcut value to main path, and pass it through a RELU activation (2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3a1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    ## Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = f, strides = (1, 1), padding='same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X) \n",
    "\n",
    "    ## Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = 1, strides = (1, 1), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    \n",
    "    ##### SHORTCUT PATH ##### \n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = 1, strides = (s, s), padding = 'valid', kernel_initializer = initializer(seed =0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ce170c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (30, 30, 1), classes = 13):\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(30, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [30, 30, 120], s = 1)\n",
    "    X = identity_block(X, 3, [30, 30, 120])\n",
    "    X = identity_block(X, 3, [30, 30, 120])\n",
    "\n",
    "    \n",
    "    ## Stage 3 (4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [120, 120, 480], s = 2)\n",
    "    X = identity_block(X, 3, [120, 120, 480])\n",
    "    X = identity_block(X, 3, [120, 120, 480])\n",
    "    X = identity_block(X, 3, [120, 120, 480])\n",
    "    \n",
    "    ## Stage 4 (6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [120, 120, 480], s = 2)\n",
    "    X = identity_block(X, 3, [120, 120, 480]) \n",
    "    X = identity_block(X, 3, [120, 120, 480])  \n",
    "    X = identity_block(X, 3, [120, 120, 480])  \n",
    "    X = identity_block(X, 3, [120, 120, 480])  \n",
    "    X = identity_block(X, 3, [120, 120, 480]) \n",
    "\n",
    "    ## Stage 5 (3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [240, 240, 960], s = 2) \n",
    "    X = identity_block(X, 3, [240, 240, 960]) \n",
    "    X = identity_block(X, 3, [240, 240, 960]) \n",
    "\n",
    "    ## AVGPOOL (1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(1, 1)(X) \n",
    "\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "054038ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 30, 30, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 36, 36, 1)   0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 15, 15, 30)   1500        ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 15, 15, 30)  120         ['conv2d_2[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 15, 15, 30)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 30)    0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 7, 7, 30)     930         ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 7, 7, 30)     8130        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 7, 7, 120)    3720        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 7, 7, 120)    3720        ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 7, 7, 120)   480         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 7, 7, 120)   480         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 7, 7, 120)    0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 7, 7, 120)    0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 30)     3630        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 30)     8130        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 7, 7, 120)    3720        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 7, 120)   480         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 7, 7, 120)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 7, 7, 120)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 7, 7, 30)     3630        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 7, 7, 30)     8130        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 7, 7, 30)    120         ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 7, 7, 30)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 7, 120)    3720        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 7, 7, 120)   480         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 7, 7, 120)    0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 7, 120)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 4, 4, 120)    14520       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 4, 4, 120)   480         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 4, 4, 120)    129720      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 4, 120)   480         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 480)    58080       ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 4, 4, 480)    58080       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 4, 480)   1920        ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 4, 480)   1920        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 4, 4, 480)    0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 4, 4, 480)    0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 4, 4, 120)    57720       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 4, 4, 120)   480         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 4, 4, 120)    129720      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 4, 4, 120)   480         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 4, 4, 480)    58080       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 4, 4, 480)   1920        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 4, 480)    0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 4, 4, 480)    0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 4, 4, 120)    57720       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 4, 4, 120)   480         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 4, 4, 120)    129720      ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 4, 4, 120)   480         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 4, 4, 480)    58080       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 4, 4, 480)   1920        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 4, 4, 480)    0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 4, 4, 480)    0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 4, 4, 120)    57720       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 4, 4, 120)   480         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 4, 4, 120)    129720      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 4, 4, 120)   480         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 4, 4, 120)    0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 4, 4, 480)    58080       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 4, 4, 480)   1920        ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 4, 4, 480)    0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 4, 4, 480)    0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 2, 2, 120)   480         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 2, 2, 120)   480         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 2, 2, 480)    230880      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 2, 2, 480)    0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 2, 2, 480)    0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 2, 2, 120)   480         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 2, 2, 120)   480         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 2, 2, 480)    0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 2, 2, 480)    0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 2, 2, 120)   480         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 2, 2, 120)   480         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 2, 2, 480)    0           ['batch_normalization_33[0][0]', \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 2, 2, 480)    0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 2, 2, 120)   480         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 2, 2, 120)   480         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 2, 2, 480)    0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 2, 2, 480)    0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 2, 2, 120)   480         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 2, 2, 120)   480         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 2, 2, 480)    0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 2, 2, 480)    0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 2, 2, 120)    57720       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 2, 2, 120)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 2, 2, 120)    129720      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 2, 2, 120)   480         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 2, 2, 120)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 2, 2, 480)    58080       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 2, 2, 480)   1920        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 2, 2, 480)    0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 2, 2, 480)    0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 1, 1, 240)    115440      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 1, 1, 240)   960         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 1, 1, 240)    518640      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 1, 1, 240)   960         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 1, 1, 960)    231360      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 1, 1, 960)    461760      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 1, 1, 960)    0           ['batch_normalization_45[0][0]', \n",
      "                                                                  'batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 1, 1, 960)    0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 1, 1, 240)    230640      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 1, 1, 240)   960         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 1, 1, 240)    518640      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 1, 1, 240)   960         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 1, 1, 960)    231360      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 1, 1, 960)    0           ['batch_normalization_49[0][0]', \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 1, 1, 960)    0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 1, 1, 240)    230640      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 1, 1, 240)   960         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 1, 1, 240)    518640      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 1, 1, 240)   960         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 1, 1, 240)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 1, 1, 960)    231360      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 1, 1, 960)   3840        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 1, 1, 960)    0           ['batch_normalization_52[0][0]', \n",
      "                                                                  'activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 1, 1, 960)    0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 960)   0           ['activation_48[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 960)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 13)           12493       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,107,413\n",
      "Trainable params: 6,079,153\n",
      "Non-trainable params: 28,260\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape = (30, 30, 1), classes = 13)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12576b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ff3384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 6s 6s/step - loss: 3.6283 - accuracy: 0.0897\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.8212 - accuracy: 0.2051\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.4592 - accuracy: 0.5641\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.7214 - accuracy: 0.7179\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.3066 - accuracy: 0.9359\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0916 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 8.0877e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 6.3335e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.1448e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, epochs = 20, batch_size = 200)\n",
    "#hist = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0d56cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(\"D:\\\\BLE_RSSI_dataset\\\\accuracy2.jpeg\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.savefig(\"D:\\\\BLE_RSSI_dataset\\\\loss2.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60706b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 1.8754 - accuracy: 0.6154\n",
      "Loss = 1.8753855228424072\n",
      "Test Accuracy = 0.6153846383094788\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006313d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
